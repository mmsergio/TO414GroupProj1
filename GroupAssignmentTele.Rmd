title: "HW6 Telemarketing"
author: "Group"
date: "3/22/2020"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Describe as-is state and to be state 

## Downloading and Prepping the Data

```{r}
library(neuralnet)
library(gmodels)
library(caret)
library(class)

#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL

str(tele)
summary(tele)
```

## Getting Data Ready for Analysis

```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
```

## Clustering the data

```{r}
tele_z <- as.data.frame(lapply(tele_norm, scale))
tele_z$yyes <- NULL
  #We use normalized so the data set is numeric
set.seed(12345)
tele_clusters <- kmeans(tele_z, 5)

tele_clusters$centers 

tele_norm$cluster <- tele_clusters$cluster
  #Cluster ID into the normalized data set

aggregate(data = tele_norm, yyes ~ cluster, mean)
  #Cluster 3 and 4 no need to build a regression, already reach the 16% threshold

#Creating 3 new data sets for each cluster

tele_norm_cl1 <- subset(tele_norm, cluster == 1)
tele_norm_cl2 <- subset(tele_norm, cluster == 2)
tele_norm_cl5 <- subset(tele_norm, cluster == 5)
```

## Building a Logistic Regression

```{r}
#For those in cluster 1
set.seed(12345)
test_cl1 <- sample(1:nrow(tele_norm_cl1), 2500)
tele_norm_cl1_train <- tele_norm_cl1[-test_cl1,]
tele_norm_cl1_test <- tele_norm_cl1[test_cl1,]
  #We create the test and train data set

reg1 <- glm(yyes ~ ., data = tele_norm_cl1_train)
reg1 <-  step(reg1, direction = "backward")
  #Optimizing the regression

tele_norm_cl1_test$yyes1 <- NULL
tele_norm_cl1_test$yyes1 <- predict(reg1, newdata = tele_norm_cl1_test, type = "response")
tele_norm_cl1_test$yyes1 <- ifelse(tele_norm_cl1_test$yyes1 > 0.5, 1, 0)
  #Create yyes column in test data set with the predictions from the regression

tele_norm_cl1_testlabels <- tele_norm_cl1[test_cl1, "yyes"]

CrossTable(x = tele_norm_cl1_testlabels, y = tele_norm_cl1_test$yyes1, prop.chisq=FALSE)
  #Esto hay que revisarlo bien porque nos estamos dejando a mucha gente que compraria



#For those in cluster 2
set.seed(12345)
test_cl2 <- sample(1:nrow(tele_norm_cl2), 3000)
tele_norm_cl2_train <- tele_norm_cl2[-test_cl2,]
tele_norm_cl2_test <- tele_norm_cl2[test_cl2,]

reg2 <- glm(yyes ~ ., data = tele_norm_cl2_train)
reg2 <-  step(reg2, direction = "backward")
  #Optimizing

tele_norm_cl2_test$yyes1 <- NULL
tele_norm_cl2_test$yyes1 <- predict(reg2, newdata = tele_norm_cl2_test, type = "response")
tele_norm_cl2_test$yyes1 <- ifelse(tele_norm_cl2_test$yyes1 > 0.5, 1, 0)

tele_norm_cl2_testlabels <- tele_norm_cl2[test_cl2, "yyes"]

CrossTable(x = tele_norm_cl2_testlabels, y = tele_norm_cl2_test$yyes1, prop.chisq=FALSE)
  #Revisar esto también



#For those in cluster 5
set.seed(12345)
test_cl5 <- sample(1:nrow(tele_norm_cl5), 1100)
tele_norm_cl5_train <- tele_norm_cl5[-test_cl5,]
tele_norm_cl5_test <- tele_norm_cl5[test_cl5,]

reg5 <- glm(yyes ~ ., data = tele_norm_cl5_train)
reg5 <-  step(reg5, direction = "backward")

tele_norm_cl5_test$yyes1 <- NULL
tele_norm_cl5_test$yyes1 <- predict(reg5, newdata = tele_norm_cl5_test, type = "response")
tele_norm_cl5_test$yyes1 <- ifelse(tele_norm_cl5_test$yyes1 > 0.5, 1, 0)

tele_norm_cl5_testlabels <- tele_norm_cl5[test_cl5, "yyes"]

CrossTable(x = tele_norm_cl5_testlabels, y = tele_norm_cl5_test$yyes1, prop.chisq=FALSE)


  #En todas nos estamos dejando a mucha gente, no tiene pinta que esta forma de predecir sea muy buena
```



## Building a KNN Model
## Building a Neural Net 

```{r}
tele_norm_cl1_train$yyes <- tele_norm_cl1_trainlabels
  #Restore the yyes column

neuralmod_cl1 <- neuralnet(yyes~., data=tele_norm_cl1_train)

tele_norm_cl1_test$yyes3 <- predict(neuralmod_cl1, tele_norm_cl1_test)
tele_norm_cl1_test$yyes3 <- ifelse(tele_norm_cl1_test$yyes3 > 0.6, 1, 0)
  #Add column with prediction

CrossTable(x = tele_norm_cl1_testlabels, y = tele_norm_cl1_test$yyes3, prop.chisq=FALSE)

confusionMatrix(as.factor(tele_norm_cl1_test$yyes3), as.factor( tele_norm_cl1_testlabels), positive = "1")
  #Notice that is inverted (compared to the Cross Table)




#CLUSTER 2
tele_norm_cl2_train$yyes <- tele_norm_cl2_trainlabels

neuralmod_cl2 <- neuralnet(yyes~., data=tele_norm_cl2_train)

tele_norm_cl2_test$yyes3 <- predict(neuralmod_cl2, tele_norm_cl2_test)
tele_norm_cl2_test$yyes3 <- ifelse(tele_norm_cl2_test$yyes3 > 0.5, 1, 0)

CrossTable(x = tele_norm_cl2_testlabels, y = tele_norm_cl2_test$yyes3, prop.chisq=FALSE)

confusionMatrix(as.factor(tele_norm_cl2_test$yyes3), as.factor(tele_norm_cl2_testlabels), positive = "1")




#CLUSTER 5
tele_norm_cl5_train$yyes <- tele_norm_cl5_trainlabels

neuralmod_cl5 <- neuralnet(yyes~., data=tele_norm_cl5_train)

tele_norm_cl5_test$yyes3 <- predict(neuralmod_cl5, tele_norm_cl5_test)
tele_norm_cl5_test$yyes3 <- ifelse(tele_norm_cl5_test$yyes3 > 0.4, 1, 0)

CrossTable(x = tele_norm_cl5_testlabels, y = tele_norm_cl5_test$yyes3, prop.chisq=FALSE)

confusionMatrix(as.factor(tele_norm_cl5_test$yyes3), as.factor(tele_norm_cl5_testlabels), positive = "1")

```




## Building a Join Prediction
```{r}
#Now we will use the predictions from the previous tests to build a joint prediction

#CLUSTER 1
tele_norm_cl1_test$yyes4 <- NULL
  #For debugging purposes
tele_norm_cl1_test$yyes4 <- ifelse((as.numeric(as.integer(tele_norm_cl1_test$yyes1)) + 
                                     as.numeric(as.integer(tele_norm_cl1_test$yyes2)) + 
                                     as.numeric(as.character(tele_norm_cl1_test$yyes3))) > 1, 1, 0 )

  #If the sum of the three predictions is more than one, it means that two or more of those three predictors is one, and thus, we get a 1 in the final prediction

CrossTable(x = tele_norm_cl1_testlabels, y = tele_norm_cl1_test$yyes4, prop.chisq=FALSE)
  #23% no está nada mal





#CLUSTER 2
tele_norm_cl2_test$yyes4 <- NULL
tele_norm_cl2_test$yyes4 <- ifelse((as.numeric(as.integer(tele_norm_cl2_test$yyes1)) + 
                                     as.numeric(as.integer(tele_norm_cl2_test$yyes2)) + 
                                     as.numeric(as.character(tele_norm_cl2_test$yyes3))) > 1, 1, 0 )

CrossTable(x = tele_norm_cl2_testlabels, y = tele_norm_cl2_test$yyes4, prop.chisq=FALSE)



#CLUSTER 5
tele_norm_cl5_test$yyes4 <- NULL
tele_norm_cl5_test$yyes4 <- ifelse((as.numeric(as.integer(tele_norm_cl5_test$yyes1)) + 
                                     as.numeric(as.integer(tele_norm_cl5_test$yyes2)) + 
                                     as.numeric(as.character(tele_norm_cl5_test$yyes3))) > 1, 1, 0 )

CrossTable(x = tele_norm_cl5_testlabels, y = tele_norm_cl5_test$yyes4, prop.chisq=FALSE)

```











