---
title: "Project2"
author: "Group 14"
date: '2022-10-30'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Introduction and business problem

    The selected data sets displays information about the client profile of customers in a telecommunications firm. This information includes demographic data about the client, data regarding payments and billing, information about the services that the client has received and finally, whether the client has renewed its contract with the firm or not (Churn variable). In this scenario the Churn variable is our response variable and we will analyze what factors affect it the most. An appropriate treatment of this information is vital to any telecommunications company as it has the potential to point out how to boost retention rate. Interesting business questions that arise given the dataset include: 

Questions for the first part:
  - How can we improve the retention rate? Financial problem (Predict, then engage those clients that we have identified that will remain, in retention promotions)
  
Questions for the second part (from clustering onwards): 
  - Which profile are we retaining and who is leaving the subscription? (Comparison among clusters and profiles)  
  - What factors tend to make clients decided NOT to renew their subscription?
  - Is there any particular client profile that is worth and feasible to target? (Best cluster in retention rate)  
  - How can we make the client do so? (We can compare clusters with similar demographics, and then compare the chunk rate of both similar clusters and maybe propose changes to the services offered to the cluster that is not performing well based on what is working to the other cluster with demographic similarities)
  - Can we identify our most valuable clients by predicting its CLV? (Maybe figure out something about the consumer lifetime value or something like that)



URL to dataset: https://www.kaggle.com/datasets/blastchar/telco-customer-churn

## Maybe add some financials to make the case first question more interesting

Month 1:
  Clients = 7000
  Monthly fix cost (rent, depreciation, wages) = 180000
  Variable costs of supplying clients with services = 12
  Total variable cost = 84000
  
  Variable costs of engaging a client in consumer retention promotions = 5
  Total cost of massive promotion = 35000
  
  Total costs = 299000 
  
  Revenues = 456116.6
  
  Profit = 157116.6
  
Month 2:
  Clients = 
  Fix cost = 180000
  Variable costs of supplying clients with services = 12
  
  
  
  
  Instead of engaging all clients in these promotions, identify through model prediction those that we should engage and reach out to them
  Then compare financials

```{r}

totalrevenues = sum(clients$MonthlyCharges)
totalrevenues
totalcost = 299000
aggregate(MonthlyCharges ~ Churn, data = clients, sum)

  
```
The company has earned  456116.6 dollars this month from the subscription service
Subtract fix and variable costs






## Data cleaning

```{r}
library(neuralnet)
library(gmodels)
library(caret)
library(class)
library(corrplot)
library(C50)
library(kernlab) 

clients <- read.csv("ClientsChurn.csv")
str(clients)
summary(clients)
  #Make factors
  #We need to decide how to deal with the NAs in the Total Charges column


clients$customerID <- NULL
  #ID is not needed
clients$gender <- as.factor(clients$gender)
clients$SeniorCitizen <- as.factor(clients$SeniorCitizen)

clients$Partner <- ifelse(clients$Partner == "Yes", 1, 0)
clients$Partner <- as.factor(clients$Partner)

clients$Dependents <- ifelse(clients$Dependents == "Yes", 1, 0)
clients$Dependents <- as.factor(clients$Dependents)

clients$PhoneService <- ifelse(clients$PhoneService == "Yes", 1, 0)
clients$PhoneService <- as.factor(clients$PhoneService)

clients$MultipleLines <- as.factor(clients$MultipleLines)
clients$InternetService <- as.factor(clients$InternetService)
clients$OnlineSecurity <- as.factor(clients$OnlineSecurity)
clients$OnlineBackup <- as.factor(clients$OnlineBackup)
clients$DeviceProtection <- as.factor(clients$DeviceProtection)
clients$TechSupport <- as.factor(clients$TechSupport)
clients$StreamingMovies <- as.factor(clients$StreamingMovies)
clients$StreamingTV <- as.factor(clients$StreamingTV)
clients$Contract <- as.factor(clients$Contract)

clients$PaperlessBilling <- ifelse(clients$PaperlessBilling == "Yes", 1, 0)
clients$PaperlessBilling <- as.factor(clients$PaperlessBilling)

clients$Churn <- ifelse(clients$Churn == "Yes", 1, 0)
clients$Churn <- as.factor(clients$Churn)

clients$PaymentMethod <- as.factor(clients$PaymentMethod)

clients$TotalCharges <- ifelse(is.na(clients$TotalCharges), median(clients$TotalCharges, na.rm = TRUE), clients$TotalCharges)
  #The NA values (a very small number) have been converted to the median

str(clients)
summary(clients)
  #All the variables but the numeric ones are made factors. Binary variables (yes or no) have been converted to 1 and 0

```

## Normalization and test/train dataframes
```{r}
clientss <- as.data.frame(model.matrix(~.-1,clients))
  #Factors are turned into dummy variables

normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

clients_norm <- as.data.frame(lapply(clientss, normalize))
  #Numeric variables are normalized

set.seed(579)
test <- sample(1:nrow(clients_norm), 2000)
  #Test made of 28% of all observations

clients_train <- clients_norm[-test,]
clients_test <- clients_norm[test,]

clients_testlabels <- clients_norm[test, "Churn1"]
clients_trainlabels <- clients_norm[-test, "Churn1"]

  #Train and test data frames created. Labels for future use. 
```

## Buildign a Logistic Regression

```{r}
reg1 <- glm(Churn1 ~ ., data = clients_train, family = "binomial")
reg1 <- step(reg1, direction = "backward")

lrprediction <- predict(reg1, newdata = clients_test, type = "response")
lrprediction <- ifelse(lrprediction > 0.5, 1, 0)

confusionMatrix(as.factor(lrprediction), as.factor(clients_test$Churn1), positive = "1")

  # Kappa = 0.48

lrprediction <- predict(reg1, newdata = clients_test, type = "response")

  #Original values are restored to build the stacked model afterwards
```

## Building a KNN prediction 

```{r}
clients_train$Churn1 <- NULL
clients_test$Churn1 <- NULL

set.seed(579)
KNNprediction <- knn(train = clients_train, test = clients_test,
                      cl = clients_trainlabels, k=sqrt(nrow(clients_train)))

CrossTable(x = clients_testlabels,y= KNNprediction,prop.chisq=FALSE)
confusionMatrix(as.factor(KNNprediction), as.factor(clients_testlabels))

  # Kappa = 0.46

clients_train$Churn1 <- clients_trainlabels
clients_test$Churn1 <- clients_testlabels
  #Churn columns is restored
```

## Neural Net

```{r}
set.seed(579)
neural_model <- neuralnet(Churn1~., data=clients_train)
ANNprediction <- predict(neural_model, newdata = clients_test)

ANNprediction <- ifelse(ANNprediction > 0.5, 1, 0)

CrossTable(x = ANNprediction, y = clients_test$Churn, prop.chisq=FALSE)
confusionMatrix(as.factor(ANNprediction), as.factor(clients_testlabels), positive = "1")

  # Kappa = 0.48

ANNprediction <- predict(neural_model, newdata = clients_test)
  # Original values restored to create the stacked model
```

## Building a Decision Tree

```{r}
treemod <- C5.0(as.factor(Churn1) ~., data = clients_train)
treepred <- predict(treemod, clients_test)

plot(treemod)

confusionMatrix(as.factor(treepred), as.factor(clients_testlabels))
  # Kappa = 0.43
```

## Building a SVM prediction

```{r}
SVM_model <- ksvm(as.factor(Churn1)~., data = clients_train, kernel = "vanilladot")
SVMprediction <- predict(SVM_model, clients_test)

confusionMatrix(as.factor(SVMprediction), as.factor(clients_testlabels))

  #Kappa = 0.47
```

## Buidling the stacked model
```{r}
allpredictions <- data.frame(lrprediction, KNNprediction, ANNprediction, SVMprediction, treepred, clients_testlabels)
summary(allpredictions)

colnames(allpredictions)[colnames(allpredictions) == "clients_testlabels"] ="Churn"
  #Dataset with all 5 predictions and the lables that contain the true values for the test dataset
set.seed(5948)
combined_test_set <- sample(1:nrow(allpredictions), 0.3*nrow(allpredictions)) 

combined_train <- allpredictions[-combined_test_set, ]
combined_test <- allpredictions[combined_test_set,]

combined_dtree <- C5.0(as.factor(Churn) ~., data = combined_train)
plot(combined_dtree)

combined_pred <- predict(combined_dtree, combined_test)
CrossTable(combined_pred, combined_test$Churn)
confusionMatrix(as.factor(combined_pred), as.factor(combined_test$Churn))

#LR and tree, but I almost forced this case with this seed 

# Kappa = 0.41
# Worse than others 
```
## Comparison of Kappa and accuracy

We just need to change this variables maybe add another thing such as sensitivity or sth

|               | Logistic Reg   | KNN      | Neural Net  |    SVM     |   Decision Tree | Stacked Model |
|:--------------|:--------------:|:--------:|:-----------:|:----------:|:---------------:|:-------------:|
|   Kappa       |  0.48          |0.45      | 0.48        |     0.47   |    0.43         | 0.41          | 
|  Accuracy     |  0.8           |  0.79    |   0.81      | 0.8        | 0.8             | 0.805         | 

It will show up properly when knitted

## Clustering of clients

```{r}
set.seed(7593)
clients_z <- as.data.frame(lapply(clients_norm, scale))

clients_clusters <- kmeans(clients_norm, 5)

clients_z$Churn1 <- NULL
clients_clusters <- kmeans(clients_z, 5)

clients_norm$cluster <- clients_clusters$cluster

clients_clusters$centers

aggregate(data = clients_norm, Churn1 ~ cluster, mean)
  #We also need to interpret this, ask in class
```

## Tuning models

```{r}
#Create models on two highest clusters
```

