---
title: "Project2"
author: "Group 14"
date: '2022-10-30'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Introduction and business problem

    The selected data sets displays information about the client profile of customers in a telecommunications firm. This information includes demographic data about the client, data regarding payments and billing, information about the services that the client has received and finally, whether the client has renewed its contract with the firm or not (Churn variable). In this scenario the Churn variable is our response variable and we will analyze what factors affect it the most. An appropriate treatment of this information is vital to any telecommunications company as it has the potential to point out how to boost retention rate. Interesting business questions that arise given the dataset include: 
  - Which profile are we retaining and who is leaving the subscription? 
  - How can we improve the retention rate? 
  - Is there any way to increase consumer loyalty? 
  - Is there any particular client profile that is worth and feasible to target?  
  - Can we determine if a recent client is going to renovate its subscription once he is in our company? How can we make the client do so? 
  - Can we identify our most valuable clients by predicting its CLV? 
  - What factors tend to make clients decided NOT to renew their subscription?
  - Given the data analysis, what changes should be made in order to retain (and increase) client rate?

URL to dataset: https://www.kaggle.com/datasets/blastchar/telco-customer-churn
>>>>>>> dd47e4fca6172d0766c44b4e3931add5e186d58c

## Data cleaning

```{r}
library(neuralnet)
library(gmodels)
library(caret)
library(class)
library(corrplot)

clients <- read.csv("ClientsChurn.csv")
str(clients)
summary(clients)
  #Make factors
  #We need to decide how to deal with the NAs in the Total Charges column


clients$customerID <- NULL
  #ID is not needed
clients$gender <- as.factor(clients$gender)
clients$SeniorCitizen <- as.factor(clients$SeniorCitizen)

clients$Partner <- ifelse(clients$Partner == "Yes", 1, 0)
clients$Partner <- as.factor(clients$Partner)

clients$Dependents <- ifelse(clients$Dependents == "Yes", 1, 0)
clients$Dependents <- as.factor(clients$Dependents)

clients$PhoneService <- ifelse(clients$PhoneService == "Yes", 1, 0)
clients$PhoneService <- as.factor(clients$PhoneService)

clients$MultipleLines <- as.factor(clients$MultipleLines)
clients$InternetService <- as.factor(clients$InternetService)
clients$OnlineSecurity <- as.factor(clients$OnlineSecurity)
clients$OnlineBackup <- as.factor(clients$OnlineBackup)
clients$DeviceProtection <- as.factor(clients$DeviceProtection)
clients$TechSupport <- as.factor(clients$TechSupport)
clients$StreamingMovies <- as.factor(clients$StreamingMovies)
clients$StreamingTV <- as.factor(clients$StreamingTV)
clients$Contract <- as.factor(clients$Contract)

clients$PaperlessBilling <- ifelse(clients$PaperlessBilling == "Yes", 1, 0)
clients$PaperlessBilling <- as.factor(clients$PaperlessBilling)

clients$Churn <- ifelse(clients$Churn == "Yes", 1, 0)
clients$Churn <- as.factor(clients$Churn)

clients$PaymentMethod <- as.factor(clients$PaymentMethod)

clients$TotalCharges <- ifelse(is.na(clients$TotalCharges), median(clients$TotalCharges, na.rm = TRUE), clients$TotalCharges)

str(clients)
summary(clients)

clientss <- as.data.frame(model.matrix(~.-1,clients))

normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

clients_norm <- as.data.frame(lapply(clientss, normalize))

set.seed(7593)
test <- sample(1:nrow(clients_norm), 2000)
clients_train <- clients_norm[-test,]
clients_test <- clients_norm[test,]
```

## Logistic Regression

```{r}
reg1 <- glm(Churn1 ~ ., data = clients_train, family = "binomial")
reg1 <- step(reg1, direction = "backward")

lrprediction <- predict(reg1, newdata = clients_test, type = "response")
lrprediction <- ifelse(lrprediction > 0.5, 1, 0)

confusionMatrix(as.factor(lrprediction), as.factor(clients_test$Churn1), positive = "1")
```

## KNN 

```{r}
clients_trainlabels <- clients_norm[-test, "Churn1"]
clients_train$Churn1 <- NULL

clients_testlabels <- clients_norm[test, "Churn1"]
clients_test$Churn1 <- NULL

set.seed(7593)
KNNprediction <- knn(train = clients_train, test = clients_test,
                      cl = clients_trainlabels, k=sqrt(nrow(clients_train)))

clients_train$Churn1 <- clients_trainlabels
clients_test$Churn1 <- clients_testlabels
  #I restore the Churn column in the train and test dataset

CrossTable(x = clients_testlabels,y= KNNprediction,prop.chisq=FALSE)
confusionMatrix(as.factor(KNNprediction), as.factor(clients_testlabels))
```

## Neural Net

```{r}
library(neuralnet)
client_test_labels <- clients_norm[test, "Churn1"]
set.seed(12345)
neural_model <- neuralnet(Churn1~., data=clients_train)
ann_pred <- predict(neural_model, newdata = clients_test)
ann_pred <- ifelse(ann_pred > 0.41, 1, 0)
CrossTable(x = ann_pred, y = clients_test$Churn, prop.chisq=FALSE)
confusionMatrix(as.factor(ann_pred), as.factor(client_test_labels), positive = "1")
```

## Decision Tree

```{r}

```

## SVM

```{r}

```

## Stacked model
```{r}
#Dataset with all 5 predictions


```

## Clustering of clients

```{r}

```

